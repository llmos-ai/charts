# Default values for llmos-agents.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
global:
  ## @param global.imageRegistry Global Docker image registry
  ##
  imageRegistry: ""
  ## @param global.imagePullSecrets Global Docker registry secret names as an array
  ## e.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  postgresql:
    fullnameOverride: ""
  security:
    ## @param global.security.allowInsecureImages Allows skipping image verification
    allowInsecureImages: true

# This is for the secretes for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: []
# This is to override the chart name.
nameOverride: "llmos-agents"
fullnameOverride: ""

langflow:
  # This section builds out the service account more information can be found here: https://kubernetes.io/docs/concepts/security/service-accounts/
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  ingress:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  securityContext:
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    runAsUser: 1000
    allowPrivilegeEscalation: false
    runAsGroup: 1000

  podSecurityContext:
    fsGroup: 1000
    runAsUser: 1000
    runAsNonRoot: true
    runAsGroup: 1000

  backend:
    logLevel: INFO
    replicaCount: 1
    service:
      type: ClusterIP
      port: 7860
    backendOnly: true
    numWorkers: 1
    image:
      registry: ghcr.io
      repository: llmos-ai/mirrored-langflowai-langflow
      imagePullPolicy: IfNotPresent
      tag: 1.5.0.post1
    command:
      - python
      - -m
      - langflow
      - run
      - --host
      - 0.0.0.0
      - --backend-only
    resources:
      requests:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 4
        memory: 8Gi
    livenessProbe:
      httpGet:
        path: /health
        port: http
      failureThreshold: 3
      periodSeconds: 15
      timeoutSeconds: 5
      initialDelaySeconds: 30
    readinessProbe:
      httpGet:
        path: /health
        port: http
      failureThreshold: 3
      periodSeconds: 15
      timeoutSeconds: 5
      initialDelaySeconds: 30
    startupProbe:
      httpGet:
        path: /health
        port: http
      failureThreshold: 3
      periodSeconds: 15
      timeoutSeconds: 5
      initialDelaySeconds: 30
    env:
      - name: LANGFLOW_PORT
        value: "7860"
      - name: LANGFLOW_ALEMBIC_LOG_FILE
        value: "/app/db/alembic.log"
      - name: LANGFLOW_UPDATE_STARTER_PROJECTS
        value: "false"
    nodeSelector: {}
    tolerations: []
    affinity: {}
    podAnnotations: {}
#      prometheus.io/scrape: "true"
#      prometheus.io/port: "9090"
#      prometheus.io/path: "/metrics"
    securityContext:
      capabilities:
        drop:
          - ALL
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      allowPrivilegeEscalation: false
      runAsGroup: 1000

    podSecurityContext:
      fsGroup: 1000
      runAsUser: 1000
      runAsNonRoot: true
      runAsGroup: 1000

    externalDatabase:
      # Compose in the SQLAlchemy format:
      # https://docs.sqlalchemy.org/en/20/core/engines.html#database-urls
      enabled: false
      driver: {}
        # value: "postgresql"
      host: {}
        # value: "postgresql"
      port: {}
        # value: "5432"
      user: {}
        # value: "langflow"
      password: {}
        # value: "langflow"
        # valueFrom:
        #   secretKeyRef:
        #    key: password
        #    name: <secret-name>
      database: {}
        # value: "langflow"

    volumes:
      - name: flows
        emptyDir: {}
      - name: tmp
        emptyDir: {}
      - name: data
        emptyDir: {}
      - name: db
        emptyDir: {}

    volumeMounts:
      - name: flows
        mountPath: /app/flows
        readOnly: false
      - name: tmp
        mountPath: /tmp
        readOnly: false
      - name: data
        mountPath: /app/data
        readOnly: false
      - name: db
        mountPath: /app/db
        readOnly: false

    sqlite:
      enabled: false
      volume:
        size: "1Gi"
        existingStorageClassName: ""
        # If you want the chart to create storage classes, then don't set
        # existingStorageClassName name and provide configuration values
        # for the storage class. The settings vary based on cloud
        # provider. Below are examples for AWS, GCP, and Azure.

        # For AWS
        # storageClass:
        #  provisioner: kubernetes.io/aws-ebs
        #  type: gp2
        #  fsType: ext4
        #  extraParams:
        #     iopsPerGB: "10"

        # For GCP
        # storageClass:
        #   provisioner: kubernetes.io/gce-pd
        #   type: pd-ssd
        #   fsType: ext4
        #   extraParams:
        #      replication-type: none

        # For Azure
        # storageClass:
        #   provisioner: kubernetes.io/azure-disk
        #   fsType: ext4
        #   type: managed-premium
        #   extraParams:
        #     storageaccounttype: Premium_LRS
        #     kind: Managed
        #     cachingmode: ReadOnly
        storageClass: {}

    # autoLogin: true|false
    # superuser: <superuser login>
    # superuserPassword: <superuser password>
    # secretKey: <encryption key, optional>
    # newUserIsActive: true|false

  frontend:
    enabled: true
    replicaCount: 1
    service:
      type: LoadBalancer
      port: 8080
      # nodePort: 30080
    image:
      registry: ghcr.io
      repository: llmos-ai/mirrored-langflowai-langflow-frontend
      tag: 1.5.0.post1
      imagePullPolicy: IfNotPresent
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 1
        memory: 2Gi
    probe:
      failureThreshold: 3
      periodSeconds: 10
      timeoutSeconds: 5
      initialDelaySeconds: 30
    nodeSelector: {}
    tolerations: []
    affinity: {}
    podAnnotations: {}
    volumes:
      - name: tmp
        emptyDir: {}
    volumeMounts:
      - name: tmp
        mountPath: /tmp
        readOnly: false

  secretProvider:
    enabled: false

postgresql:
  enabled: true
  name: postgres
  auth:
    enablePostgresUser: true
    postgresPassword: ""
    username: &postgresUser "llmos-agents"
    password: ""
    database: "llmos_agents"
  image:
    registry: ghcr.io
    repository: llmos-ai/mirrored-bitnami-postgresql
    tag: 17.5.0-debian-12-r20
  ## @param architecture PostgreSQL architecture (`standalone` or `replication`)
  architecture: replication
  ## Replication configuration
  ## Ignored if `architecture` is `standalone`
  primary:
    resources:
      requests:
        cpu: 200m
        memory: 256Mi
      limits:
        cpu: 2
        memory: 1024Mi
    persistence:
      enabled: true
      storageClass: ""
      accessModes:
        - ReadWriteOnce
      size: 8Gi
  readReplicas:
    persistence:
      enabled: true
      storageClass: ""
      accessModes:
        - ReadWriteOnce
      size: 8Gi

weaviate:
  enabled: true
  image:
    registry: ghcr.io
    repo: llmos-ai/mirrored-semitechnologies-weaviate
    tag: 1.32.1
  resources:
    requests:
      cpu: 200m
      memory: 300Mi
    limits:
      cpu: 2
      memory: 2Gi
  storage:
    size: 32Gi
    storageClassName: ""
  service:
    name: weaviate
    ports:
      - name: http
        protocol: TCP
        port: 80
    type: NodePort

  grpcService:
    enabled: true
    name: weaviate-grpc
    ports:
      - name: grpc
        protocol: TCP
        port: 50051
    type: NodePort

  serviceMonitor:
    enabled: false
    interval: 30s
    scrapeTimeout: 10s
  initContainers:
    sysctlInitContainer:
      enabled: true
      sysctlVmMaxMapCount: 524288
      image:
        registry: ghcr.io
        repo: llmos-ai/mirrored-library-nginx
        tag: 1.24.0-alpine
        pullPolicy: IfNotPresent

langfuse:
  enabled: true
  # Core Langfuse Configuration
  langfuse:
    # Logging configuration
    logging:
      # -- Set the log level for the application (trace, debug, info, warn, error, fatal)
      level: info

    # -- Used to hash API keys. Can be configured by value or existing secret reference. To generate a new salt, run `openssl rand -base64 32`.
    salt:
      value: ""
      secretKeyRef:
        name: "llmos-agents-langfuse-init"
        key: "LANGFUSE_SALT"
    smtp:
      # -- SMTP connection URL. See [documentation](https://langfuse.com/self-hosting/transactional-emails)
      connectionUrl: ""
      # -- From address for emails. Required if connectionUrl is set.
      fromAddress: ""

    replicas: 1
    resources:
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 200m
        memory: 256Mi

    # -- List of additional environment variables to be added to all langfuse deployments. See [documentation](https://langfuse.com/docs/deployment/self-host#configuring-environment-variables) for details.
    additionalEnv:
      - name: LANGFUSE_INIT_ORG_ID
        valueFrom:
          secretKeyRef:
            name: llmos-agents-langfuse-init
            key: LANGFUSE_INIT_ORG_ID
      - name: LANGFUSE_INIT_ORG_NAME
        valueFrom:
          secretKeyRef:
            name: llmos-agents-langfuse-init
            key: LANGFUSE_INIT_ORG_NAME
      - name: LANGFUSE_INIT_PROJECT_ID
        valueFrom:
          secretKeyRef:
            name: llmos-agents-langfuse-init
            key: LANGFUSE_INIT_PROJECT_ID
      - name: LANGFUSE_INIT_PROJECT_NAME
        valueFrom:
          secretKeyRef:
            name: llmos-agents-langfuse-init
            key: LANGFUSE_INIT_PROJECT_NAME
      - name: LANGFUSE_INIT_PROJECT_PUBLIC_KEY
        valueFrom:
          secretKeyRef:
            name: llmos-agents-langfuse-init
            key: LANGFUSE_INIT_PROJECT_PUBLIC_KEY
      - name: LANGFUSE_INIT_PROJECT_SECRET_KEY
        valueFrom:
          secretKeyRef:
            name: llmos-agents-langfuse-init
            key: LANGFUSE_INIT_PROJECT_SECRET_KEY
      - name: LANGFUSE_INIT_USER_EMAIL
        value: admin@1block.ai
      - name: LANGFUSE_INIT_USER_PASSWORD
        valueFrom:
          secretKeyRef:
            name: llmos-agents-langfuse-init
            key: LANGFUSE_INIT_USER_PASSWORD
    # Web deployment configuration
    web:
      image:
        repository: ghcr.io/llmos-ai/mirrored-langfuse-langfuse
        pullPolicy: IfNotPresent
      service:
        type: LoadBalancer
        port: 8090

      # -- Resources for the langfuse web pods. Defaults to the global resources
      resources:
        limits:
          cpu: 2
          memory: 4Gi
        requests:
          cpu: 200m
          memory: 256Mi
      livenessProbe:
        path: "/api/public/health"
        initialDelaySeconds: 20
        periodSeconds: 10
        timeoutSeconds: 5
        failureThreshold: 3
        successThreshold: 1

      readinessProbe:
        path: "/api/public/ready"
        initialDelaySeconds: 20
        periodSeconds: 10
        timeoutSeconds: 5
        failureThreshold: 3
        successThreshold: 1

    # Worker deployment configuration
    worker:
      image:
        repository: ghcr.io/llmos-ai/mirrored-langfuse-langfuse-worker
        pullPolicy: IfNotPresent
      resources:
        limits:
          cpu: 2
          memory: 4Gi
        requests:
          cpu: 200m
          memory: 256Mi

    # NextAuth configuration
    nextauth:
      # -- When deploying to production, set the `nextauth.url` value to the canonical URL of your site.
      url: http://localhost:3000
      # -- Used to encrypt the NextAuth.js JWT, and to hash email verification tokens. Can be configured by value or existing secret reference.
      secret:
        value: ""
        secretKeyRef:
          name: "llmos-agents-langfuse-init"
          key: "LANGFUSE_NEXT_AUTH"

  # PostgreSQL Configuration
  postgresql:
    deploy: false

    # -- PostgreSQL host to connect to. If postgresql.deploy is true, this will be set automatically based on the release name.
    host: "llmos-agents-postgresql-primary.llmos-agents"
    # -- Port of the postgres server to use. Defaults to 5432.
    port: 5432
    # -- Additional database connection arguments
    args: ""

    # -- If `postgresql.deploy` is set to false, Connection string of your Postgres database used for database migrations. Use this if you want to use a different user for migrations or use connection pooling on DATABASE_URL. For large deployments, configure the database user with long timeouts as migrations might need a while to complete.
    directUrl: ""

    # -- If your database user lacks the CREATE DATABASE permission, you must create a shadow database and configure the "SHADOW_DATABASE_URL". This is often the case if you use a Cloud database. Refer to the Prisma docs for detailed instructions.
    shadowDatabaseUrl: ""

    # Authentication configuration
    auth:
      # -- Username to use to connect to the postgres database deployed with Langfuse. In case `postgresql.deploy` is set to `true`, the user will be created automatically.
      username: *postgresUser
      # -- Password to use to connect to the postgres database deployed with Langfuse. In case `postgresql.deploy` is set to `true`, the password will be set automatically.
      password: ""
      # -- If you want to use an existing secret for the postgres password, set the name of the secret here. (`postgresql.auth.username` and `postgresql.auth.password` will be ignored and picked up from this secret).
      existingSecret: "llmos-agents-postgresql"
      # -- The key in the existing secret that contains the password.
      secretKeys:
        userPasswordKey: password
      # -- Database name to use for Langfuse.
      database: llmos_agents_langfuse
      # -- Additional database connection arguments
      args: ""

    # Migration configuration
    migration:
      # -- Whether to run automatic migrations on startup
      autoMigrate: true

  # Key-Value Store / Redis Configuration
  redis:
    # -- Enable valkey deployment (via Bitnami Helm Chart). If you want to use a Redis or Valkey server already deployed, set to false.
    deploy: true

    image:
      registry: ghcr.io
      repository: llmos-ai/mirrored-bitnami-valkey
      tag: 8.0.2-debian-12-r2

    # -- Redis host to connect to. If redis.deploy is true, this will be set automatically based on the release name.
    host: "llmos-agents-redis-primary.llmos-agents"
    # -- Redis port to connect to.
    port: 6379

    # Redis TLS configuration
    tls:
      # -- Set to `true` to enable TLS/SSL encrypted connection to the Redis server
      enabled: false
      # -- Path to the CA certificate file for TLS verification
      caPath: ""
      # -- Path to the client certificate file for mutual TLS authentication
      certPath: ""
      # -- Path to the client private key file for mutual TLS authentication
      keyPath: ""

    # Authentication configuration
    auth:
      # -- Username to use to connect to the redis database deployed with Langfuse. In case `redis.deploy` is set to `true`, the user will be created automatically. Set to null for an empty username in the connection string.
      username: "default"
      # -- Configure the password by value or existing secret reference. Use URL-encoded passwords or avoid special characters in the password.
      password: "llmos-agents"
      # -- If you want to use an existing secret for the redis password, set the name of the secret here. (`redis.auth.password` will be ignored and picked up from this secret).
      existingSecret: ""
      # -- The key in the existing secret that contains the password.
      existingSecretPasswordKey: ""

      database: 0

    # Subchart specific settings
    architecture: standalone
    primary:
      # -- Extra flags for the valkey deployment. Must include `--maxmemory-policy noeviction`.
      extraFlags:
        - "--maxmemory-policy noeviction"

  # ClickHouse Configuration
  clickhouse:
    # -- Enable ClickHouse deployment (via Bitnami Helm Chart). If you want to use an external Clickhouse server (or a managed one), set this to false
    deploy: true

    image:
      registry: ghcr.io
      repository: llmos-ai/mirrored-bitnami-clickhouse
      tag: 25.2.1-debian-12-r0

    # -- ClickHouse host to connect to. If clickhouse.deploy is true, this will be set automatically based on the release name.
    host: "llmos-agents-clickhouse.llmos-agents"
    # -- ClickHouse HTTP port to connect to.
    httpPort: 8123
    # -- ClickHouse native port to connect to.
    nativePort: 9000

    # Authentication configuration
    auth:
      # -- Username for the ClickHouse user.
      username: default
      # -- Password for the ClickHouse user.
      password: "llmos-agents"
      # -- If you want to use an existing secret for the ClickHouse password, set the name of the secret here. (`clickhouse.auth.username` and `clickhouse.auth.password` will be ignored and picked up from this secret).
      existingSecret: ""
      # -- The key in the existing secret that contains the password.
      existingSecretKey: ""

    # Migration configuration
    migration:
      # -- Migration URL (TCP protocol) for clickhouse
      url: ""
      # -- Set to true to establish SSL connection for migration
      ssl: false
      # -- Whether to run automatic ClickHouse migrations on startup
      autoMigrate: true

    # -- Whether to run ClickHouse commands ON CLUSTER
    clusterEnabled: true

    # -- Subchart specific settings
    shards: 1  # Fixed - Langfuse does not support sharding
    # -- Number of replicas to use for the ClickHouse cluster. 1 corresponds to a single, non-HA deployment.
    replicaCount: 3
    # -- The resources preset to use for the ClickHouse cluster.
    resourcesPreset: xlarge  # options are nano, micro, small, medium, large, xlarge, 2xlarge

    zookeeper:
      image:
        registry: ghcr.io
        repository: llmos-ai/mirrored-bitnami-zookeeper
        tag: 3.9.3-debian-12-r8

  # S3/MinIO Configuration
  s3:
    # -- Enable MinIO deployment (via Bitnami Helm Chart). If you want to use a custom BlobStorage, e.g. S3, set to false.
    deploy: true

    image:
      registry: ghcr.io
      repository: llmos-ai/mirrored-bitnami-minio
      tag: 2024.12.18-debian-12-r1

    # -- S3 bucket to use for all uploads. Can be overridden per upload type.
    bucket: ""
    # -- S3 region to use for all uploads. Can be overridden per upload type.
    region: "auto"
    # -- S3 endpoint to use for all uploads. Can be overridden per upload type.
    endpoint: "http://llmos-agents-s3.llmos-agents:9000"
    # -- Whether to force path style on requests. Required for MinIO. Can be overridden per upload type.
    forcePathStyle: true
    # -- S3 accessKeyId to use for all uploads. Can be overridden per upload type.
    accessKeyId:
      value: ""
      secretKeyRef:
        name: ""
        key: ""
    # -- S3 secretAccessKey to use for all uploads. Can be overridden per upload type.
    secretAccessKey:
      value: ""
      secretKeyRef:
        name: ""
        key: ""

    # S3 Concurrency Configuration
    concurrency:
      # -- Maximum number of concurrent read operations to S3. Defaults to 50.
      reads: 50
      # -- Maximum number of concurrent write operations to S3. Defaults to 50.
      writes: 50

    # Event Upload Configuration
    eventUpload:
      # -- S3 bucket to use for event uploads.
      bucket: ""
      # -- Prefix to use for event uploads within the bucket.
      prefix: ""
      # -- S3 region to use for event uploads.
      region: ""
      # -- S3 endpoint to use for event uploads.
      endpoint: ""
      # -- Whether to force path style on requests. Required for MinIO.
      forcePathStyle: null
      # -- S3 accessKeyId to use for event uploads.
      accessKeyId:
        value: ""
        secretKeyRef:
          name: ""
          key: ""
      # -- S3 secretAccessKey to use for event uploads.
      secretAccessKey:
        value: ""
        secretKeyRef:
          name: ""
          key: ""

    # Batch Export Configuration
    batchExport:
      # -- Enable batch export.
      enabled: true
      # -- S3 bucket to use for batch exports.
      bucket: ""
      # -- Prefix to use for batch exports within the bucket.
      prefix: ""
      # -- S3 region to use for batch exports.
      region: ""
      # -- S3 endpoint to use for batch exports.
      endpoint: ""
      # -- Whether to force path style on requests. Required for MinIO.
      forcePathStyle: null
      # -- S3 accessKeyId to use for batch exports.
      accessKeyId:
        value: ""
        secretKeyRef:
          name: ""
          key: ""
      # -- S3 secretAccessKey to use for batch exports.
      secretAccessKey:
        value: ""
        secretKeyRef:
          name: ""
          key: ""

    # Media Upload Configuration
    mediaUpload:
      # -- Enable media uploads.
      enabled: true
      # -- S3 bucket to use for media uploads.
      bucket: ""
      # -- Prefix to use for media uploads within the bucket.
      prefix: ""
      # -- S3 region to use for media uploads.
      region: ""
      # -- S3 endpoint to use for media uploads.
      endpoint: ""
      # -- Whether to force path style on requests. Required for MinIO.
      forcePathStyle: null
      # -- S3 accessKeyId to use for media uploads.
      accessKeyId:
        value: ""
        secretKeyRef:
          name: ""
          key: ""
      # -- S3 secretAccessKey to use for media uploads.
      secretAccessKey:
        value: ""
        secretKeyRef:
          name: ""
          key: ""
      # -- Maximum content length for media uploads. Defaults to 1GB.
      maxContentLength: 1000000000
      # -- Expiry time for download URLs. Defaults to 1 hour.
      downloadUrlExpirySeconds: 3600

    # MinIO subchart specific settings
    defaultBuckets: langfuse
    auth:
      # -- root username
      # rootUser: ""
      # -- Password for MinIO root user
      # rootPassword: ""
      # -- If you want to use an existing secret for the root user password, set the name of the secret here. (`s3.auth.rootUser` and `s3.auth.rootPassword` will be ignored and picked up from this secret).
      existingSecret: "llmos-agents-langfuse-init"
      # -- Key where the Minio root user is being stored inside the existing secret `s3.auth.existingSecret`
      rootUserSecretKey: "LANGFUSE_S3_ROOT_USER"
      # -- Key where the Minio root user password is being stored inside the existing secret `s3.auth.existingSecret`
      rootPasswordSecretKey: "LANGFUSE_S3_ROOT_PASSWORD"

  # Additional manifests
  extraManifests: []
